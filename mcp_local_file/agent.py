# agent.py
import os
from openai import OpenAI
import json
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# MCP ì„œë²„ì˜ ë„êµ¬ë“¤ì„ OpenAI Functionìœ¼ë¡œ ë³€í™˜
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "ë¡œì»¬ íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "ì½ì„ íŒŒì¼ì˜ ê²½ë¡œ"
                    }
                },
                "required": ["file_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "list_directory",
            "description": "ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ê³¼ í´ë” ëª©ë¡ì„ ë³´ì—¬ì¤ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "directory_path": {
                        "type": "string",
                        "description": "ì¡°íšŒí•  ë””ë ‰í† ë¦¬ ê²½ë¡œ"
                    }
                },
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_in_files",
            "description": "íŠ¹ì • ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "search_query": {
                        "type": "string",
                        "description": "ê²€ìƒ‰í•  í…ìŠ¤íŠ¸"
                    },
                    "directory": {
                        "type": "string",
                        "description": "ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ"
                    },
                    "file_extensions": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "ê²€ìƒ‰í•  íŒŒì¼ í™•ì¥ì"
                    }
                },
                "required": ["search_query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_file_info",
            "description": "íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "íŒŒì¼ ê²½ë¡œ"
                    }
                },
                "required": ["file_path"]
            }
        }
    }
]

class FileAgent:
    def __init__(self):
        self.conversation_history = []
        # MCP ì„œë²„ ë„êµ¬ë“¤ì„ ì‹¤ì œ í•¨ìˆ˜ë¡œ ë§¤í•‘
        from file_server import read_file, list_directory, search_in_files, get_file_info
        self.tool_functions = {
            "read_file": read_file,
            "list_directory": list_directory,
            "search_in_files": search_in_files,
            "get_file_info": get_file_info
        }
    
    def chat(self, user_message: str) -> str:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬"""
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })
        
        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì„ íƒìƒ‰í•˜ê³  ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
                    
ì‚¬ìš©ìê°€ íŒŒì¼ì´ë‚˜ ë””ë ‰í† ë¦¬ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´:
1. ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”
2. ê²°ê³¼ë¥¼ ë¶„ì„í•´ì„œ ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
3. ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì¡°í•©í•´ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤

ì£¼ì˜ì‚¬í•­:
- íŒŒì¼ ê²½ë¡œëŠ” ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤
- ë³´ì•ˆì„ ìœ„í•´ ì‹œìŠ¤í…œ íŒŒì¼ì€ ì½ì§€ ë§ˆì„¸ìš”
- ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚´ìš©ë§Œ ì²˜ë¦¬í•˜ì„¸ìš”"""
                }
            ] + self.conversation_history,
            tools=TOOLS,
            tool_choice="auto"
        )
        
        response_message = response.choices[0].message
        tool_calls = response_message.tool_calls
        
        # ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°
        if tool_calls:
            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append(response_message)
            
            # ê° ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                print(f"\nğŸ”§ ë„êµ¬ ì‚¬ìš©: {function_name}")
                print(f"   ì¸ì: {function_args}")
                
                # ë„êµ¬ ì‹¤í–‰
                # FunctionTool ê°ì²´ëŠ” .fn ì†ì„±ìœ¼ë¡œ ì‹¤ì œ í•¨ìˆ˜ì— ì ‘ê·¼
                tool = self.tool_functions[function_name]
                if hasattr(tool, 'fn'):
                    # FastMCPì˜ FunctionToolì¸ ê²½ìš°
                    function_response = tool.fn(**function_args)
                else:
                    # ì¼ë°˜ í•¨ìˆ˜ì¸ ê²½ìš°
                    function_response = tool(**function_args)
                
                # ë„êµ¬ ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                self.conversation_history.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response
                })
            
            # ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•´ì„œ ë‹¤ì‹œ GPT í˜¸ì¶œ
            second_response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì„ íƒìƒ‰í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."}
                ] + self.conversation_history
            )
            
            final_message = second_response.choices[0].message.content
            self.conversation_history.append({
                "role": "assistant",
                "content": final_message
            })
            
            return final_message
        
        else:
            # ë„êµ¬ í˜¸ì¶œ ì—†ì´ ë°”ë¡œ ë‹µë³€
            self.conversation_history.append({
                "role": "assistant",
                "content": response_message.content
            })
            return response_message.content

def main():
    agent = FileAgent()
    
    print("=" * 60)
    print("ğŸ¤– ë¡œì»¬ íŒŒì¼ AI Agent")
    print("=" * 60)
    print("ë¡œì»¬ íŒŒì¼ì„ ì½ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
    print("'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.\n")
    
    while True:
        user_input = input("\nğŸ‘¤ You: ")
        
        if user_input.lower() in ['quit', 'exit']:
            print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        
        response = agent.chat(user_input)
        print(f"\nğŸ¤– Agent: {response}")

if __name__ == "__main__":
    main()