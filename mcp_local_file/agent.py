# agent.py
import os
from openai import OpenAI
import json
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# MCP ì„œë²„ì˜ ë„êµ¬ë“¤ì„ OpenAI Functionìœ¼ë¡œ ë³€í™˜
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "read_file",
            "description": "ë¡œì»¬ íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "ì½ì„ íŒŒì¼ì˜ ê²½ë¡œ"
                    }
                },
                "required": ["file_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "list_directory",
            "description": "ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ê³¼ í´ë” ëª©ë¡ì„ ë³´ì—¬ì¤ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "directory_path": {
                        "type": "string",
                        "description": "ì¡°íšŒí•  ë””ë ‰í† ë¦¬ ê²½ë¡œ"
                    }
                },
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_in_files",
            "description": "íŠ¹ì • ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "search_query": {
                        "type": "string",
                        "description": "ê²€ìƒ‰í•  í…ìŠ¤íŠ¸"
                    },
                    "directory": {
                        "type": "string",
                        "description": "ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ"
                    },
                    "file_extensions": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "ê²€ìƒ‰í•  íŒŒì¼ í™•ì¥ì"
                    }
                },
                "required": ["search_query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_file_info",
            "description": "íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "íŒŒì¼ ê²½ë¡œ"
                    }
                },
                "required": ["file_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "analyze_image",
            "description": "ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤ (ì‚¬ë¬¼, ì¥ë©´, í…ìŠ¤íŠ¸ ë“± ì¸ì‹)",
            "parameters": {
                "type": "object",
                "properties": {
                    "image_path": {
                        "type": "string",
                        "description": "ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ"
                    },
                    "question": {
                        "type": "string",
                        "description": "ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸",
                        "default": "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”?"
                    }
                },
                "required": ["image_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "compare_images",
            "description": "ë‘ ì´ë¯¸ì§€ë¥¼ ë¹„êµí•©ë‹ˆë‹¤",
            "parameters": {
                "type": "object",
                "properties": {
                    "image_path1": {"type": "string"},
                    "image_path2": {"type": "string"},
                    "question": {"type": "string"}
                },
                "required": ["image_path1", "image_path2"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "extract_text_from_image",
            "description": "ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (OCR)",
            "parameters": {
                "type": "object",
                "properties": {
                    "image_path": {"type": "string"}
                },
                "required": ["image_path"]
            }
        }
    }
]

class FileAgent:
    def __init__(self):
        self.conversation_history = []
        # MCP ì„œë²„ ë„êµ¬ë“¤ì„ ì‹¤ì œ í•¨ìˆ˜ë¡œ ë§¤í•‘
        from file_server import read_file, list_directory, search_in_files, get_file_info, analyze_image, compare_images, extract_text_from_image
        self.tool_functions = {
            "read_file": read_file,
            "list_directory": list_directory,
            "search_in_files": search_in_files,
            "get_file_info": get_file_info,
            "analyze_image": analyze_image,
            "compare_images": compare_images,
            "extract_text_from_image": extract_text_from_image
        }
    
    def _call_tool(self, function_name: str, function_args: dict) -> str:
        """ë„êµ¬ ì‹¤í–‰ (ì´ë¯¸ì§€ ì²˜ë¦¬ í¬í•¨)"""
        
        result = self.tool_functions[function_name](**function_args)
        
        # ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        if result.startswith("IMAGE_DATA:"):
            return self._handle_image_analysis(result)
        elif result.startswith("COMPARE_IMAGES:"):
            return self._handle_image_comparison(result)
        elif result.startswith("EXTRACT_TEXT:"):
            return self._handle_text_extraction(result)
        
        return result
    
    def _handle_image_analysis(self, result: str) -> str:
        """ì´ë¯¸ì§€ ë¶„ì„ ì²˜ë¦¬"""
        try:
            # íŒŒì‹±: IMAGE_DATA:mime_type:base64_data|QUESTION:question
            parts = result.split("|QUESTION:")
            image_part = parts[0].replace("IMAGE_DATA:", "")
            question = parts[1] if len(parts) > 1 else "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”?"
            
            mime_type, image_data = image_part.split(":", 1)
            
            # GPT-4o Vision í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4.1-mini",  # ë˜ëŠ” "gpt-4o-mini"
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": question
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{mime_type};base64,{image_data}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
    
    def _handle_image_comparison(self, result: str) -> str:
        """ì´ë¯¸ì§€ ë¹„êµ ì²˜ë¦¬"""
        try:
            parts = result.split("|")
            image1_data = parts[0].replace("COMPARE_IMAGES:", "")
            image2_data = parts[1]
            question = parts[2].replace("QUESTION:", "") if len(parts) > 2 else "ì°¨ì´ì ì€?"
            
            mime1, data1 = image1_data.split(":", 1)
            mime2, data2 = image2_data.split(":", 1)
            
            response = client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": question},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{mime1};base64,{data1}"
                                }
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{mime2};base64,{data2}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ì´ë¯¸ì§€ ë¹„êµ ì‹¤íŒ¨: {str(e)}"
    
    def _handle_text_extraction(self, result: str) -> str:
        """OCR ì²˜ë¦¬"""
        try:
            parts = result.replace("EXTRACT_TEXT:", "").split(":", 1)
            mime_type, image_data = parts
            
            response = client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{mime_type};base64,{image_data}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"
        
    def chat(self, user_message: str) -> str:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬"""

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # ìµœê·¼ 5ê°œë§Œ ìœ ì§€ (í† í° ì ˆì•½)
        recent_history = self.conversation_history[-10:]  # ìµœê·¼ 10ê°œ (user+assistant ìŒ 5ê°œ)

        # OpenAI API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # gpt-4 ëŒ€ì‹  gpt-4o-mini ì‚¬ìš© (ë” ì €ë ´í•˜ê³  ë¹ ë¦„)
            messages=[
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì„ íƒìƒ‰í•˜ê³  ë¶„ì„í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ íŒŒì¼ì´ë‚˜ ë””ë ‰í† ë¦¬ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´:
1. ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”
2. ê²°ê³¼ë¥¼ ë¶„ì„í•´ì„œ ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
3. ì—¬ëŸ¬ ë„êµ¬ë¥¼ ì¡°í•©í•´ì„œ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤

ì£¼ì˜ì‚¬í•­:
- íŒŒì¼ ê²½ë¡œëŠ” ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤
- ë³´ì•ˆì„ ìœ„í•´ ì‹œìŠ¤í…œ íŒŒì¼ì€ ì½ì§€ ë§ˆì„¸ìš”
- ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚´ìš©ë§Œ ì²˜ë¦¬í•˜ì„¸ìš”"""
                }
            ] + recent_history,  # ì „ì²´ íˆìŠ¤í† ë¦¬ ëŒ€ì‹  ìµœê·¼ ê²ƒë§Œ!
            tools=TOOLS,
            tool_choice="auto"
        )
        
        response_message = response.choices[0].message
        tool_calls = response_message.tool_calls
        
        # ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°
        if tool_calls:
            # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.conversation_history.append(response_message)
            
            # ê° ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                print(f"\nğŸ”§ ë„êµ¬ ì‚¬ìš©: {function_name}")
                print(f"   ì¸ì: {function_args}")
                
                # ë„êµ¬ ì‹¤í–‰
                # FunctionTool ê°ì²´ëŠ” .fn ì†ì„±ìœ¼ë¡œ ì‹¤ì œ í•¨ìˆ˜ì— ì ‘ê·¼
                tool = self.tool_functions[function_name]
                if hasattr(tool, 'fn'):
                    # FastMCPì˜ FunctionToolì¸ ê²½ìš°
                    function_response = tool.fn(**function_args)
                else:
                    # ì¼ë°˜ í•¨ìˆ˜ì¸ ê²½ìš°
                    function_response = tool(**function_args)
                
                # ë„êµ¬ ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                self.conversation_history.append({
                    "tool_call_id": tool_call.id,
                    "role": "tool",
                    "name": function_name,
                    "content": function_response
                })
            
            # ë„êµ¬ ê²°ê³¼ë¥¼ í¬í•¨í•´ì„œ ë‹¤ì‹œ GPT í˜¸ì¶œ
            second_response = client.chat.completions.create(
                model="gpt-4.1",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œì„ íƒìƒ‰í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."}
                ] + self.conversation_history
            )
            
            final_message = second_response.choices[0].message.content
            self.conversation_history.append({
                "role": "assistant",
                "content": final_message
            })
            
            return final_message
        
        else:
            # ë„êµ¬ í˜¸ì¶œ ì—†ì´ ë°”ë¡œ ë‹µë³€
            self.conversation_history.append({
                "role": "assistant",
                "content": response_message.content
            })
            return response_message.content

def main():
    agent = FileAgent()
    
    print("=" * 60)
    print("ğŸ¤– ë¡œì»¬ íŒŒì¼ AI Agent")
    print("=" * 60)
    print("ë¡œì»¬ íŒŒì¼ì„ ì½ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.")
    print("'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.\n")
    
    while True:
        user_input = input("\nğŸ‘¤ You: ")
        
        if user_input.lower() in ['quit', 'exit']:
            print("ğŸ‘‹ ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        
        response = agent.chat(user_input)
        print(f"\nğŸ¤– Agent: {response}")

if __name__ == "__main__":
    main()