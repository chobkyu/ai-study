"""
Error Debugger API with LangGraph
PHP ì—ëŸ¬ â†’ FastAPI â†’ LangGraph Agent â†’ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ë¶„ì„
"""
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, List, Annotated, TypedDict
import os
import re
from pathlib import Path
from dotenv import load_dotenv
import json

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_core.tools import tool

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o", temperature=0.3)

# FastAPI ì•±
app = FastAPI(
    title="Error Debugger API with LangGraph",
    description="LangGraphë¡œ ì²´ê³„ì ì¸ ì—ëŸ¬ ë¶„ì„",
    version="4.0.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ========== Pydantic Models ==========

class ErrorRequest(BaseModel):
    error_type: str = Field(..., description="ì—ëŸ¬ íƒ€ì…")
    error_message: str = Field(..., description="ì—ëŸ¬ ë©”ì‹œì§€")
    stack_trace: str = Field(..., description="ì „ì²´ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤")
    input_params: Optional[str] = Field(None, description="ì…ë ¥ íŒŒë¼ë¯¸í„°")
    server_base_path: str = Field(
        default="/Users/fanding/develop/legacy-php-api",
        description="ì„œë²„ ì½”ë“œ ê¸°ë³¸ ê²½ë¡œ"
    )


# ========== LangChain Tools ==========

@tool
def read_file(file_path: str) -> str:
    """íŒŒì¼ì˜ ì „ì²´ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤."""
    try:
        # /home/fanding â†’ /Users/fanding ê²½ë¡œ ë³€í™˜ (macOS)
        if file_path.startswith('/home/fanding'):
            file_path = file_path.replace('/home/fanding', '/Users/fanding')

        if not os.path.isabs(file_path):
            possible_bases = [
                "/Users/fanding/develop/legacy-php-api",
                "/Users/fanding/develop/ppp",
                os.getcwd()
            ]
            for base in possible_bases:
                full_path = os.path.join(base, file_path)
                if os.path.exists(full_path):
                    file_path = full_path
                    break

        print(f"[DEBUG] read_file: {file_path}, exists={os.path.exists(file_path)}")

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            print(f"[DEBUG] read_file: ì½ì€ ê¸¸ì´ = {len(content)} bytes")
            return content
    except Exception as e:
        return f"ERROR: {str(e)}"


@tool
def search_files(directory: str, pattern: str = "*.php") -> str:
    """ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        import glob
        if not os.path.isabs(directory):
            directory = os.path.abspath(directory)
        search_pattern = os.path.join(directory, "**", pattern)
        files = glob.glob(search_pattern, recursive=True)
        return json.dumps(files[:30], ensure_ascii=False)
    except Exception as e:
        return json.dumps([f"ERROR: {str(e)}"], ensure_ascii=False)


@tool
def grep_code(file_path: str, search_term: str) -> str:
    """íŒŒì¼ì—ì„œ íŠ¹ì • ì½”ë“œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    try:
        # /home/fanding â†’ /Users/fanding ê²½ë¡œ ë³€í™˜ (macOS)
        if file_path.startswith('/home/fanding'):
            file_path = file_path.replace('/home/fanding', '/Users/fanding')

        content = read_file.invoke({"file_path": file_path})
        if content.startswith("ERROR"):
            return content
        lines = content.split('\n')
        results = []
        for i, line in enumerate(lines, 1):
            if search_term.lower() in line.lower():
                results.append(f"Line {i}: {line.strip()}")
        return "\n".join(results[:15]) if results else f"'{search_term}' ì—†ìŒ"
    except Exception as e:
        return f"ERROR: {str(e)}"


# ========== LangGraph State ==========

from operator import add

class AgentState(TypedDict):
    messages: Annotated[list, add]  # add operatorë¡œ ë©”ì‹œì§€ ëˆ„ì 
    error_info: dict
    analysis_result: Optional[str]


# ========== LangGraph Nodes ==========

def find_primary_error_file(stack_trace: str, base_paths: list) -> tuple:
    """ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ì—ì„œ í•µì‹¬ ì—ëŸ¬ íŒŒì¼ ì°¾ê¸°"""
    import re
    exclude = ['/system/', '/vendor/', '/core/', 'CodeIgniter.php', 'index.php', '/bootstrap/']

    for line in stack_trace.split('\n'):
        match = re.search(r'#\d+\s+([^(]+\.php)\((\d+)\)', line)
        if match:
            file_path, line_no = match.groups()
            if any(p in file_path for p in exclude):
                continue

            for base in base_paths:
                for sub in ['', 'application/controllers/rest', 'application/controllers', 'application/models']:
                    full = Path(base) / sub / Path(file_path).name
                    if full.exists():
                        return str(full), line_no
    return None, None


def analyze_node(state: AgentState):
    """ì—ëŸ¬ ë¶„ì„ ë…¸ë“œ"""
    print("\nğŸ¤– AI ì—ì´ì „íŠ¸ ë¶„ì„ ì¤‘...")

    messages = state["messages"]
    error_info = state["error_info"]

    # ë””ë²„ê¹…: í˜„ì¬ messages ìƒíƒœ í™•ì¸
    print(f"[DEBUG] Current messages count: {len(messages)}")
    for i, msg in enumerate(messages):
        msg_type = type(msg).__name__
        has_tool_calls = hasattr(msg, 'tool_calls') and msg.tool_calls
        print(f"  [{i}] {msg_type}, tool_calls={has_tool_calls}")

    # ğŸ”§ ê²½ë¡œ ë³€í™˜: /home/fanding â†’ /Users/fanding (macOS ë¡œì»¬ ê°œë°œ í™˜ê²½)
    stack_trace = error_info['stack_trace'].replace('/home/fanding', '/Users/fanding')
    error_info['stack_trace'] = stack_trace

    # ğŸ¯ í•µì‹¬ ì—ëŸ¬ íŒŒì¼ ë¨¼ì € ì½ê¸°
    base_paths = [
        '/Users/fanding/develop/legacy-php-api',
        '/Users/fanding/develop/ppp',
        error_info.get('server_base_path', '')
    ]

    primary_file, error_line = find_primary_error_file(stack_trace, base_paths)

    context_code = ""
    if primary_file:
        print(f"ğŸ“ ì‹œì‘ì : {primary_file}:{error_line}")
        try:
            with open(primary_file, 'r', encoding='utf-8') as f:
                context_code = f.read()[:5000]
        except Exception as e:
            print(f"âš ï¸  íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")

    # ğŸ”‘ ì²« ë²ˆì§¸ í˜¸ì¶œì¸ì§€ í™•ì¸
    is_first_call = len(messages) == 0

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    if is_first_call:
        # ì²« ë²ˆì§¸: ë„êµ¬ ì‚¬ìš© ê°€ëŠ¥
        system_msg = SystemMessage(content=f"""ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ PHP ë°±ì—”ë“œ ì—ëŸ¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì¤‘ìš” ì •ë³´:**
- ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜: /Users/fanding/develop/legacy-php-api
- ì•„ë˜ ì—ëŸ¬ íŒŒì¼ì´ ì´ë¯¸ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤: {primary_file if primary_file else 'ì—†ìŒ'}
- ì œê³µëœ íŒŒì¼ë§Œìœ¼ë¡œ ì¶©ë¶„í•˜ë©´ ì¦‰ì‹œ ë¶„ì„í•˜ì„¸ìš”

**ë¶„ì„ ë°©ë²•:**
1. **ì—ëŸ¬ê°€ ë°œìƒí•œ ì •í™•í•œ ë¼ì¸ê³¼ ë³€ìˆ˜ íŠ¹ì •**
   - ì–´ë–¤ ë³€ìˆ˜/ê°ì²´ê°€ ë¬¸ì œì¸ê°€?
   - ì™œ nullì´ê±°ë‚˜ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ê°’ì¸ê°€?
   - ì…ë ¥ íŒŒë¼ë¯¸í„° ì¤‘ ì–´ë–¤ ê°’ì´ ì˜ëª» ë“¤ì–´ì™”ëŠ”ê°€?

2. **ê·¼ë³¸ ì›ì¸ íŒŒì•…**
   - í˜¸ì¶œ ì²´ì¸ ë¶„ì„ (ì–´ë””ì„œ ë„˜ì–´ì˜¨ ê°’ì¸ê°€?)
   - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ìƒ ì™œ ì´ëŸ° ìƒí™©ì´ ë°œìƒí–ˆëŠ”ê°€?
   - DB ì¿¼ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆëŠ”ê°€? ì¡°ê±´ë¬¸ ì²´í¬ê°€ ëˆ„ë½ëëŠ”ê°€?

3. **ì¬ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ê°œì„ ì•ˆ ì œì‹œ**
   - ì¦‰ì‹œ í•´ê²°: ì—ëŸ¬ê°€ ì•ˆ ë‚˜ë„ë¡ ìˆ˜ì •
   - ì¥ê¸° ê°œì„ : ë” ì•ˆì „í•œ ì½”ë“œ êµ¬ì¡° ì œì•ˆ

**ì¶œë ¥ í˜•ì‹:**
## ğŸ” ì—ëŸ¬ ìœ„ì¹˜
- íŒŒì¼: [íŒŒì¼ëª…]:[ë¼ì¸ë²ˆí˜¸]
- í•¨ìˆ˜: [í•¨ìˆ˜ëª…]
- ë¬¸ì œ ë³€ìˆ˜: [ë³€ìˆ˜ëª…]

## ğŸ’¥ ì›ì¸ ë¶„ì„
**ì¦‰ì‹œ ì›ì¸:**
- [ì–´ë–¤ ë³€ìˆ˜ê°€ null/ì˜ëª»ëœ ê°’ì¸ì§€]
- [ì™œ ê·¸ëŸ° ê°’ì´ ë“¤ì–´ì™”ëŠ”ì§€]

**ê·¼ë³¸ ì›ì¸:**
- [ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ìƒ ë¬¸ì œì ]
- [í˜¸ì¶œ ê²½ë¡œ ì¶”ì ]

## ğŸ”§ í•´ê²° ë°©ë²•
**ì¦‰ì‹œ ìˆ˜ì • (Hot Fix):**
```php
// ìˆ˜ì • ì „
[ê¸°ì¡´ ì½”ë“œ]

// ìˆ˜ì • í›„
[ìˆ˜ì •ëœ ì½”ë“œ + ì£¼ì„ìœ¼ë¡œ ì„¤ëª…]
```

**ì¥ê¸° ê°œì„ ì•ˆ:**
- [ë” ì•ˆì „í•œ ì½”ë“œ êµ¬ì¡°]
- [validation ì¶”ê°€ ì œì•ˆ]
- [ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ ]

**ê·œì¹™:**
- ì œê³µëœ ì—ëŸ¬ íŒŒì¼ ì½”ë“œë¥¼ ìš°ì„  ë¶„ì„
- ì •ë§ í•„ìš”í•œ ê²½ìš°ë§Œ read_fileë¡œ ì¶”ê°€ íŒŒì¼ ì¡°íšŒ (ìµœëŒ€ 1-2ê°œ)
- êµ¬ì²´ì ì¸ ë³€ìˆ˜ëª…ê³¼ ë¼ì¸ ë²ˆí˜¸ ì–¸ê¸‰
- "íŒŒì¼ì´ ì—†ë‹¤"ê³  ë§í•˜ì§€ ë§ê³  ì œê³µëœ ì½”ë“œë¥¼ ë¶„ì„
""")

        # ì—ëŸ¬ ì •ë³´
        content = f"""ì—ëŸ¬ ë¶„ì„:

íƒ€ì…: {error_info['error_type']}
ë©”ì‹œì§€: {error_info['error_message']}

ìŠ¤íƒ:
{error_info['stack_trace']}

íŒŒë¼ë¯¸í„°: {error_info.get('input_params', 'ì—†ìŒ')}
"""

        if context_code:
            content += f"""

ğŸ“„ ì—ëŸ¬ íŒŒì¼ ({primary_file}:{error_line}):
```php
{context_code}
```
"""

        error_msg = HumanMessage(content=content)

        llm_with_tools = llm.bind_tools([read_file, search_files, grep_code])
        response = llm_with_tools.invoke([system_msg, error_msg])

    else:
        # ë‘ ë²ˆì§¸ ì´í›„: ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë¶„ì„ (ë„êµ¬ ì—†ì´)
        prompt_msg = HumanMessage(content="""ë„êµ¬ ì¡°íšŒ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì—ëŸ¬ ë¶„ì„ì„ ì‘ì„±í•˜ì„¸ìš”.

**ì¶œë ¥ í˜•ì‹:**
## ğŸ” ì—ëŸ¬ ìœ„ì¹˜
- íŒŒì¼: [íŒŒì¼ëª…]:[ë¼ì¸ë²ˆí˜¸]
- í•¨ìˆ˜: [í•¨ìˆ˜ëª…]
- ë¬¸ì œ ë³€ìˆ˜: [ë³€ìˆ˜ëª…]

## ğŸ’¥ ì›ì¸ ë¶„ì„
**ì¦‰ì‹œ ì›ì¸:**
- [ì–´ë–¤ ë³€ìˆ˜ê°€ null/ì˜ëª»ëœ ê°’ì¸ì§€]
- [ì™œ ê·¸ëŸ° ê°’ì´ ë“¤ì–´ì™”ëŠ”ì§€]

**ê·¼ë³¸ ì›ì¸:**
- [ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ìƒ ë¬¸ì œì ]
- [í˜¸ì¶œ ê²½ë¡œ ì¶”ì ]

## ğŸ”§ í•´ê²° ë°©ë²•
**ì¦‰ì‹œ ìˆ˜ì • (Hot Fix):**
```php
// ìˆ˜ì • ì „
[ê¸°ì¡´ ì½”ë“œ]

// ìˆ˜ì • í›„
[ìˆ˜ì •ëœ ì½”ë“œ + ì£¼ì„ìœ¼ë¡œ ì„¤ëª…]
```

**ì¥ê¸° ê°œì„ ì•ˆ:**
- [ë” ì•ˆì „í•œ ì½”ë“œ êµ¬ì¡°]
- [validation ì¶”ê°€ ì œì•ˆ]
- [ì—ëŸ¬ í•¸ë“¤ë§ ê°œì„ ]

**ì¤‘ìš”: ë” ì´ìƒ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ì§€ ë§ê³ , ì§€ê¸ˆ ë°”ë¡œ ìƒì„¸í•œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì„±í•˜ì„¸ìš”.**
""")

        # messages ìˆœì„œ ìœ ì§€: [AI(tool_calls), ToolMessage, ...]
        response = llm.invoke(messages + [prompt_msg])

    return {"messages": messages + [response]}


def tool_node_wrapper(state: AgentState):
    """íˆ´ ì‹¤í–‰ ë…¸ë“œ"""
    print(f"ğŸ”§ íˆ´ ì‹¤í–‰ ì¤‘...")

    messages = state["messages"]

    # ë””ë²„ê¹…: ë„êµ¬ ì‹¤í–‰ ì „ messages í™•ì¸
    print(f"[DEBUG] Before tool execution, messages count: {len(messages)}")
    for i, msg in enumerate(messages):
        msg_type = type(msg).__name__
        has_tool_calls = hasattr(msg, 'tool_calls') and msg.tool_calls
        print(f"  [{i}] {msg_type}, tool_calls={has_tool_calls}")

    tools = [read_file, search_files, grep_code]
    tool_node = ToolNode(tools)
    result = tool_node.invoke(state)

    # ë””ë²„ê¹…: messages êµ¬ì¡° í™•ì¸
    print(f"[DEBUG] After tool execution, result messages count: {len(result.get('messages', []))}")
    for i, msg in enumerate(result.get('messages', [])):
        msg_type = type(msg).__name__
        has_tool_calls = hasattr(msg, 'tool_calls') and msg.tool_calls
        print(f"  [{i}] {msg_type}, tool_calls={has_tool_calls}")

    return result


def should_continue(state: AgentState):
    """ê³„ì†í• ì§€ ê²°ì •"""
    messages = state["messages"]
    last_message = messages[-1]

    # AI ë©”ì‹œì§€ ì¹´ìš´íŠ¸ (ìµœëŒ€ 5ë²ˆë§Œ ë°˜ë³µ)
    ai_count = sum(1 for m in messages if isinstance(m, AIMessage))
    if ai_count >= 5:
        print(f"âš ï¸  ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ({ai_count}íšŒ), ê°•ì œ ì¢…ë£Œ")
        return "end"

    # íˆ´ í˜¸ì¶œì´ ìˆìœ¼ë©´ ê³„ì†
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"
    return "end"


def extract_result(state: AgentState):
    """ìµœì¢… ê²°ê³¼ ì¶”ì¶œ"""
    messages = state["messages"]

    # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì°¾ê¸°
    for msg in reversed(messages):
        if isinstance(msg, AIMessage) and msg.content:
            return {"analysis_result": msg.content}

    return {"analysis_result": "ë¶„ì„ ì‹¤íŒ¨"}


# ========== LangGraph ìƒì„± ==========

workflow = StateGraph(AgentState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("analyze", analyze_node)
workflow.add_node("tools", tool_node_wrapper)
workflow.add_node("extract", extract_result)

# ì—£ì§€ ì„¤ì •
workflow.set_entry_point("analyze")
workflow.add_conditional_edges(
    "analyze",
    should_continue,
    {
        "tools": "tools",
        "end": "extract"
    }
)
workflow.add_edge("tools", "analyze")
workflow.add_edge("extract", END)

# ì»´íŒŒì¼
graph = workflow.compile()


# ========== Helper Functions ==========

def _extract_file_locations(stack_trace: str, base_path: str) -> List[dict]:
    """ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ì—ì„œ íŒŒì¼ ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ"""
    locations = []

    # Python
    python_pattern = r'File\s+"([^"]+)",\s+line\s+(\d+)(?:,\s+in\s+(\w+))?'
    for match in re.findall(python_pattern, stack_trace):
        file_path, line_num, function = match
        if base_path in file_path or os.path.isabs(file_path):
            locations.append({
                'file': file_path,
                'line': int(line_num),
                'function': function or None,
                'language': 'python'
            })

    # PHP
    php_pattern = r'([/\w\-\.]+\.php)[\(:]+(\d+)\)?'
    for match in re.findall(php_pattern, stack_trace):
        file_path, line_num = match
        if base_path in file_path or os.path.isabs(file_path):
            locations.append({
                'file': file_path,
                'line': int(line_num),
                'function': None,
                'language': 'php'
            })

    return locations


# ========== FastAPI Endpoints ==========

@app.get("/health")
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "ok",
        "service": "error-debugger",
        "version": "4.0.0"
    }


@app.post("/analyze")
async def analyze_error(request: ErrorRequest):
    """LangGraphë¡œ ì—ëŸ¬ ë¶„ì„"""
    try:
        print("\n" + "="*80)
        print("ğŸš€ ì—ëŸ¬ ë¶„ì„ ì‹œì‘")
        print(f"íƒ€ì…: {request.error_type}")
        print(f"ë©”ì‹œì§€: {request.error_message}")
        print("="*80)

        # íŒŒì¼ ìœ„ì¹˜ ì¶”ì¶œ
        file_locations = _extract_file_locations(
            request.stack_trace,
            request.server_base_path
        )

        print(f"\nğŸ“ íŒŒì¼ ìœ„ì¹˜: {len(file_locations)}ê°œ")
        for loc in file_locations:
            print(f"  - {loc['file']}:{loc['line']}")

        if not file_locations:
            return {
                "success": False,
                "error": "ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ì—ì„œ íŒŒì¼ ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                "analysis": None
            }

        # LangGraph ì‹¤í–‰
        initial_state = {
            "messages": [],
            "error_info": {
                "error_type": request.error_type,
                "error_message": request.error_message,
                "stack_trace": request.stack_trace,
                "input_params": request.input_params,
                "server_base_path": request.server_base_path
            },
            "analysis_result": None
        }

        # ê·¸ë˜í”„ ì‹¤í–‰
        final_state = None
        for state in graph.stream(initial_state, {"recursion_limit": 15}):
            final_state = state
            print(f"\n[DEBUG] State keys: {state.keys()}")

        print(f"\n[DEBUG] Final state: {final_state}")

        # ê²°ê³¼ ì¶”ì¶œ
        if final_state and "extract" in final_state:
            analysis = final_state["extract"]["analysis_result"]
            print(f"[DEBUG] Got analysis from extract node: {analysis[:100]}...")
        elif final_state:
            # ë§ˆì§€ë§‰ ìƒíƒœì—ì„œ ë¶„ì„ ê²°ê³¼ ì°¾ê¸°
            last_state = list(final_state.values())[0]
            print(f"[DEBUG] Last state keys: {last_state.keys() if isinstance(last_state, dict) else 'not a dict'}")

            # messagesì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
            if "messages" in last_state:
                messages = last_state["messages"]
                print(f"[DEBUG] Messages count: {len(messages)}")
                for msg in reversed(messages):
                    if isinstance(msg, AIMessage) and msg.content:
                        analysis = msg.content
                        print(f"[DEBUG] Found AI message: {analysis[:100]}...")
                        break
                else:
                    analysis = last_state.get("analysis_result", "ë¶„ì„ ì‹¤íŒ¨")
            else:
                analysis = last_state.get("analysis_result", "ë¶„ì„ ì‹¤íŒ¨")
        else:
            analysis = "ë¶„ì„ ì‹¤íŒ¨"

        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"\nğŸ“ ê²°ê³¼:\n{analysis}")
        print("\n" + "="*80)

        return {
            "success": True,
            "file_locations": file_locations,
            "analysis": analysis
        }

    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬: {str(e)}")
        print("="*80)
        raise HTTPException(
            status_code=500,
            detail=f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )


if __name__ == "__main__":
    import uvicorn
    print("ğŸš€ Error Debugger API (LangGraph)")
    print("   - LangGraph State Machine")
    print("   - ê°„ê²°í•œ ë¶„ì„ ê²°ê³¼")
    print("   - Port: 9000")
    uvicorn.run(app, host="0.0.0.0", port=9000)
